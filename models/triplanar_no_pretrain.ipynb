{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to run on WSL2, hence the directml usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: 1\n",
      "Current device: privateuseone:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import nrrd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch_directml as tdml\n",
    "\n",
    "print(f'Available devices: {tdml.device_count()}')\n",
    "print(f'Current device: {tdml.device()}')\n",
    "dml = tdml.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        raw_labels = [(*(os.path.splitext(file)[0].split(\"_\")[1:-1]), file) for file in os.listdir(data_dir)]\n",
    "\n",
    "        self.labels = pd.DataFrame(data=raw_labels, columns=[\"pid\", \"age\", \"tbv\", \"filename\"])\n",
    "        self.labels[[\"age\", \"tbv\"]] = self.labels[[\"age\", \"tbv\"]].astype(float)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        entry = self.labels.iloc[idx]\n",
    "        raster = nrrd.read(os.path.join(self.data_dir, entry[\"filename\"]))[0]\n",
    "        raster = (raster - np.mean(raster)) / np.std(raster) # Standardize the data\n",
    "\n",
    "        return {\"pid\": entry[\"pid\"], \"age\": entry[\"age\"], \"tbv\": entry[\"tbv\"], \"raster\": raster}\n",
    "\n",
    "class RasterNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RasterNet, self).__init__()\n",
    "\n",
    "        # First layer is triplanar as used in S3PNet:\n",
    "        # https://www.sciencedirect.com/science/article/pii/S1077314219301791\n",
    "\n",
    "        self.trpl = nn.Sequential( # 128x128x128 -> 32x40x40\n",
    "            nn.Conv2d(128, 32, kernel_size=9, stride=3, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential( # 96x40x40 -> 192x10x10\n",
    "            nn.Conv2d(96, 192, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential( # 192x10x10 -> 384x5x5\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential( # 384x5x5 -> 768x3x3\n",
    "            nn.Conv2d(384, 768, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential( # 768x3x3 -> 1536x1x1\n",
    "            nn.Conv2d(768, 1536, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1536),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(1536, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, base):\n",
    "        base = base.squeeze().float().to(dml)\n",
    "\n",
    "        xy = self.trpl(base)\n",
    "        yz = self.trpl(torch.transpose(base, 2, 1))\n",
    "        xz = self.trpl(torch.transpose(base, 1, 3))\n",
    "\n",
    "        x = self.conv1(torch.cat((xy, yz, xz), dim=1))\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return self.linear(x.squeeze())\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Training Loss: 36765.8250, Validation Loss: 23184.8271\n",
      "Epoch [2/10000], Training Loss: 7673.3729, Validation Loss: 160778.2812\n",
      "Epoch [3/10000], Training Loss: 5113.3029, Validation Loss: 32292.3574\n",
      "Epoch [4/10000], Training Loss: 2095.3804, Validation Loss: 63056.9355\n",
      "Epoch [5/10000], Training Loss: 1446.9366, Validation Loss: 18765.0918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 41\u001b[0m training_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unknown error -2147467259",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = RasterDataset(data_dir=\"../aug_dataset\")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "model = RasterNet().to(dml)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10000\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=15)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    training_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        rasters = data[\"raster\"].float().unsqueeze(1).to(dml)\n",
    "        tbvs = data[\"tbv\"].float().to(dml)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        rasters = rasters\n",
    "\n",
    "        predictions = model(rasters).squeeze()\n",
    "        loss = criterion(predictions, tbvs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    validation_loss = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            rasters = data[\"raster\"].float().unsqueeze(1).to(dml)\n",
    "            tbvs = data[\"tbv\"].float().to(dml)\n",
    "\n",
    "            predictions = model(rasters).squeeze()\n",
    "            loss = criterion(predictions, tbvs)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "    train_loss = training_loss/len(train_dataloader)\n",
    "    val_loss = validation_loss/len(test_dataloader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    if early_stopper(validation_loss):\n",
    "        break\n",
    "\n",
    "plt.plot(train_loss_list, label=\"Training Loss\", linewidth=3)\n",
    "plt.plot(val_loss_list, label=\"Validation Loss\", linewidth=3)\n",
    "plt.legend(\"Training Loss\", \"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "torch.save(model.state_dict(), \"last_run_weights.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b07e8231a1c09af6c251322c63d0939bf4169cb77497fa1dd2c4891068f3259a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
